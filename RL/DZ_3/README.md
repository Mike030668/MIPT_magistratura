## Задача: обучить агента действовать в средах с непрерывным пространством действий, используя алгоритм SAC (Soft Actor Critic) или PPO (Proximal Policy Optimization).

_________________________

### Для задания был исполmзован фреймворк *`google-deepmind-acme`*, который позволил провести тесты и обучение на CPU в среде `pybullet-gym` - `Walker2DBulletEnv`

- В данном [ноутбуке](https://github.com/Mike030668/MIPT_magistratura/blob/main/RL/DZ_3/DZ_3_pybullet_tests.ipynb) были проведены тесты соеды и подбор вариантов управления агентом на основе формул
  <img src="images/Видео_test1.gif" alt="gif"  width="350"/>  <img src="images/Видео_test2.gif" alt="gif"  width="350"/> <img src="images/Видео_test3.gif" alt="gif"  width="350"/> 

